{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaef76e8",
   "metadata": {},
   "source": [
    "# Sprint 1: Schema Design and Prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c59b5d3",
   "metadata": {},
   "source": [
    "#### Initial configuration and conection to duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22aa272f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB is now connected to the persistent database file at:\n",
      "-> ../data/lakehouse\\lakehouse.duckdb\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- Configuration ---\n",
    "# Define paths to your raw data and the future lakehouse layers\n",
    "RAW_DATA_PATH = '../data/raw'\n",
    "LAKEHOUSE_PATH = '../data/lakehouse'\n",
    "LAKEHOUSE_DB_PATH = os.path.join(LAKEHOUSE_PATH, 'lakehouse.duckdb')\n",
    "\n",
    "# Create the lakehouse directories if they don't exist\n",
    "os.makedirs(os.path.join(LAKEHOUSE_PATH, 'bronze'), exist_ok=True)\n",
    "os.makedirs(os.path.join(LAKEHOUSE_PATH, 'silver'), exist_ok=True)\n",
    "os.makedirs(os.path.join(LAKEHOUSE_PATH, 'gold'), exist_ok=True)\n",
    "\n",
    "# --- DuckDB Connection ---\n",
    "con = duckdb.connect(database=LAKEHOUSE_DB_PATH, read_only=False)\n",
    "\n",
    "print(f\"DuckDB is now connected to the persistent database file at:\")\n",
    "print(f\"-> {LAKEHOUSE_DB_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be6104",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Step 1: Data Exploration\n",
    "\n",
    "\n",
    "## 1. Data Exploration: Inspecting the Raw Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e567a",
   "metadata": {},
   "source": [
    "#### Explore a MITMA Mobility File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d91dc8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample of Mobility Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>periodo</th>\n",
       "      <th>origen</th>\n",
       "      <th>destino</th>\n",
       "      <th>distancia</th>\n",
       "      <th>actividad_origen</th>\n",
       "      <th>actividad_destino</th>\n",
       "      <th>estudio_origen_posible</th>\n",
       "      <th>estudio_destino_posible</th>\n",
       "      <th>residencia</th>\n",
       "      <th>renta</th>\n",
       "      <th>edad</th>\n",
       "      <th>sexo</th>\n",
       "      <th>viajes</th>\n",
       "      <th>viajes_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230508</td>\n",
       "      <td>03</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>2.521</td>\n",
       "      <td>2.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230508</td>\n",
       "      <td>18</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>6.162</td>\n",
       "      <td>7.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230508</td>\n",
       "      <td>19</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>6.162</td>\n",
       "      <td>6.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230508</td>\n",
       "      <td>20</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>9.030</td>\n",
       "      <td>11.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230508</td>\n",
       "      <td>07</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>10-50</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>2.685</td>\n",
       "      <td>30.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fecha periodo    origen destino distancia actividad_origen  \\\n",
       "0  20230508      03  01009_AM   01001     0.5-2        frecuente   \n",
       "1  20230508      18  01009_AM   01001     0.5-2        frecuente   \n",
       "2  20230508      19  01009_AM   01001     0.5-2        frecuente   \n",
       "3  20230508      20  01009_AM   01001     0.5-2        frecuente   \n",
       "4  20230508      07  01009_AM   01001     10-50        frecuente   \n",
       "\n",
       "  actividad_destino estudio_origen_posible  estudio_destino_posible  \\\n",
       "0              casa                     no                    False   \n",
       "1              casa                     no                    False   \n",
       "2              casa                     no                    False   \n",
       "3              casa                     no                    False   \n",
       "4              casa                     no                    False   \n",
       "\n",
       "  residencia renta edad sexo  viajes  viajes_km  \n",
       "0         01   <10   NA   NA   2.521      2.703  \n",
       "1         01   <10   NA   NA   6.162      7.997  \n",
       "2         01   <10   NA   NA   6.162      6.208  \n",
       "3         01   <10   NA   NA   9.030     11.528  \n",
       "4         01   <10   NA   NA   2.685     30.125  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Schema of Mobility Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "      <th>null</th>\n",
       "      <th>key</th>\n",
       "      <th>default</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fecha</td>\n",
       "      <td>BIGINT</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>periodo</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>origen</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>destino</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distancia</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actividad_origen</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>actividad_destino</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>estudio_origen_posible</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>estudio_destino_posible</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>residencia</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>renta</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>edad</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sexo</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>viajes</td>\n",
       "      <td>DOUBLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>viajes_km</td>\n",
       "      <td>DOUBLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                column_name column_type null   key default extra\n",
       "0                     fecha      BIGINT  YES  None    None  None\n",
       "1                   periodo     VARCHAR  YES  None    None  None\n",
       "2                    origen     VARCHAR  YES  None    None  None\n",
       "3                   destino     VARCHAR  YES  None    None  None\n",
       "4                 distancia     VARCHAR  YES  None    None  None\n",
       "5          actividad_origen     VARCHAR  YES  None    None  None\n",
       "6         actividad_destino     VARCHAR  YES  None    None  None\n",
       "7    estudio_origen_posible     VARCHAR  YES  None    None  None\n",
       "8   estudio_destino_posible     BOOLEAN  YES  None    None  None\n",
       "9                residencia     VARCHAR  YES  None    None  None\n",
       "10                    renta     VARCHAR  YES  None    None  None\n",
       "11                     edad     VARCHAR  YES  None    None  None\n",
       "12                     sexo     VARCHAR  YES  None    None  None\n",
       "13                   viajes      DOUBLE  YES  None    None  None\n",
       "14                viajes_km      DOUBLE  YES  None    None  None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path to one of the daily mobility files\n",
    "mobility_file_path = os.path.join(RAW_DATA_PATH, 'mitma', '20230508_Viajes_distritos.csv.gz')\n",
    "\n",
    "# Use DuckDB to directly read and describe the gzipped CSV\n",
    "# The 'read_csv_auto' function is powerful and can infer types, headers, etc.\n",
    "query = f\"\"\"--sql\n",
    "    SELECT *\n",
    "    FROM read_csv_auto('{mobility_file_path}')\n",
    "    LIMIT 5;\n",
    "\"\"\"\n",
    "df_mobility_sample = con.execute(query).df()\n",
    "\n",
    "print(\"--- Sample of Mobility Data ---\")\n",
    "display(df_mobility_sample)\n",
    "\n",
    "print(\"\\n--- Schema of Mobility Data ---\")\n",
    "# Let's get the column names and data types as inferred by DuckDB\n",
    "query_desc = f\"DESCRIBE SELECT * FROM read_csv_auto('{mobility_file_path}');\"\n",
    "df_mobility_schema = con.execute(query_desc).df()\n",
    "display(df_mobility_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b476d0d",
   "metadata": {},
   "source": [
    "#### Explore the MITMA Zoning File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fd8b76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample of Zoning Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>Alegría-Dulantzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01002</td>\n",
       "      <td>Amurrio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01004_AM</td>\n",
       "      <td>Artziniega agregacion de municipios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01009_AM</td>\n",
       "      <td>Asparrena agregacion de municipios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01010</td>\n",
       "      <td>Ayala/Aiara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                 name\n",
       "0     01001                     Alegría-Dulantzi\n",
       "1     01002                              Amurrio\n",
       "2  01004_AM  Artziniega agregacion de municipios\n",
       "3  01009_AM   Asparrena agregacion de municipios\n",
       "4     01010                          Ayala/Aiara"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Schema of Zoning Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "      <th>null</th>\n",
       "      <th>key</th>\n",
       "      <th>default</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  column_name column_type null   key default extra\n",
       "0          ID     VARCHAR  YES  None    None  None\n",
       "1        name     VARCHAR  YES  None    None  None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path to the district names file\n",
    "zoning_file_path = os.path.join(RAW_DATA_PATH, 'mitma', 'nombres_distritos.csv')\n",
    "\n",
    "# Load and inspect the zoning file\n",
    "query = f\"\"\"--sql\n",
    "    SELECT *\n",
    "    FROM read_csv_auto('{zoning_file_path}')\n",
    "    LIMIT 5;\n",
    "\"\"\"\n",
    "df_zoning_sample = con.execute(query).df()\n",
    "\n",
    "print(\"--- Sample of Zoning Data ---\")\n",
    "display(df_zoning_sample)\n",
    "\n",
    "print(\"\\n--- Schema of Zoning Data ---\")\n",
    "query_desc = f\"DESCRIBE SELECT * FROM read_csv_auto('{zoning_file_path}');\"\n",
    "df_zoning_schema = con.execute(query_desc).df()\n",
    "display(df_zoning_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab40d70",
   "metadata": {},
   "source": [
    "#### Explore the INE Economic File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc9f995a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample of INE Economic Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provincias</th>\n",
       "      <th>Ramas de actividad</th>\n",
       "      <th>Periodo</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albacete</td>\n",
       "      <td>PRODUCTO INTERIOR BRUTO A PRECIOS DE MERCADO</td>\n",
       "      <td>2022 (P)</td>\n",
       "      <td>9.485.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albacete</td>\n",
       "      <td>PRODUCTO INTERIOR BRUTO A PRECIOS DE MERCADO</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.853.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albacete</td>\n",
       "      <td>PRODUCTO INTERIOR BRUTO A PRECIOS DE MERCADO</td>\n",
       "      <td>2020</td>\n",
       "      <td>8.010.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albacete</td>\n",
       "      <td>PRODUCTO INTERIOR BRUTO A PRECIOS DE MERCADO</td>\n",
       "      <td>2019</td>\n",
       "      <td>8.627.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albacete</td>\n",
       "      <td>PRODUCTO INTERIOR BRUTO A PRECIOS DE MERCADO</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.285.269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Provincias                            Ramas de actividad   Periodo  \\\n",
       "0   Albacete  PRODUCTO INTERIOR BRUTO A PRECIOS DE MERCADO  2022 (P)   \n",
       "1   Albacete  PRODUCTO INTERIOR BRUTO A PRECIOS DE MERCADO      2021   \n",
       "2   Albacete  PRODUCTO INTERIOR BRUTO A PRECIOS DE MERCADO      2020   \n",
       "3   Albacete  PRODUCTO INTERIOR BRUTO A PRECIOS DE MERCADO      2019   \n",
       "4   Albacete  PRODUCTO INTERIOR BRUTO A PRECIOS DE MERCADO      2018   \n",
       "\n",
       "       Total  \n",
       "0  9.485.962  \n",
       "1  8.853.382  \n",
       "2  8.010.434  \n",
       "3  8.627.212  \n",
       "4  8.285.269  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path to the INE GDP file\n",
    "ine_file_path = os.path.join(RAW_DATA_PATH, 'ine', 'ine_provincial_gdp_2000-2022.csv') # Or whatever you named it\n",
    "\n",
    "# This file is semicolon-separated, so we tell DuckDB explicitly\n",
    "query = f\"\"\"--sql\n",
    "    SELECT *\n",
    "    FROM read_csv_auto('{ine_file_path}', sep=';')\n",
    "    LIMIT 5;\n",
    "\"\"\"\n",
    "df_ine_sample = con.execute(query).df()\n",
    "\n",
    "print(\"--- Sample of INE Economic Data ---\")\n",
    "display(df_ine_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff111fef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Step 2: Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca75740",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.1 Bronze ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebe7d7",
   "metadata": {},
   "source": [
    "#### 2.1.1 Mobility files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5805c395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following mobility files to ingest:\n",
      " - 20230508_Viajes_distritos.csv.gz\n",
      " - 20230509_Viajes_distritos.csv.gz\n",
      " - 20230510_Viajes_distritos.csv.gz\n",
      " - 20230511_Viajes_distritos.csv.gz\n",
      " - 20230512_Viajes_distritos.csv.gz\n",
      " - 20230513_Viajes_distritos.csv.gz\n",
      " - 20230514_Viajes_distritos.csv.gz\n",
      "\n",
      "✅ Successfully ingested 7 files into a single Bronze Parquet file:\n",
      "   -> ../data/lakehouse\\bronze\\mobility_sample_week.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. Define File Paths ---\n",
    "# Source: All gzipped CSV files for the week in the raw/mitma directory\n",
    "mitma_raw_glob_path = os.path.join(RAW_DATA_PATH, 'mitma', '*_Viajes_distritos.csv.gz')\n",
    "# Destination: A single Parquet file in the bronze layer\n",
    "bronze_mobility_path = os.path.join(LAKEHOUSE_PATH, 'bronze', 'mobility_sample_week.parquet')\n",
    "\n",
    "# --- 2. Find all the raw mobility files ---\n",
    "mobility_files = glob.glob(mitma_raw_glob_path)\n",
    "# It's good practice to print the files you've found to ensure it's working\n",
    "print(\"Found the following mobility files to ingest:\")\n",
    "for f in mobility_files:\n",
    "    print(f\" - {os.path.basename(f)}\")\n",
    "\n",
    "# --- 3. Construct and Execute the Ingestion Query ---\n",
    "# The query reads all CSVs at once, adds metadata, and copies the result to a Parquet file.\n",
    "# DuckDB's read_csv_auto can take a list of files.\n",
    "# We also use 'filename=true' to automatically add a column with the source filename.\n",
    "ingestion_query = f\"\"\"--sql\n",
    "    COPY (\n",
    "        SELECT \n",
    "            *,\n",
    "            CURRENT_TIMESTAMP AS ingestion_timestamp\n",
    "        FROM read_csv_auto({mobility_files}, filename=true, all_varchar=true) -- <--- THIS IS THE FIX\n",
    "    ) TO '{bronze_mobility_path}' (FORMAT PARQUET, OVERWRITE_OR_IGNORE 1);\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "con.execute(ingestion_query)\n",
    "\n",
    "print(f\"\\n✅ Successfully ingested {len(mobility_files)} files into a single Bronze Parquet file:\")\n",
    "print(f\"   -> {bronze_mobility_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe05e80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying the Bronze Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>periodo</th>\n",
       "      <th>origen</th>\n",
       "      <th>destino</th>\n",
       "      <th>distancia</th>\n",
       "      <th>actividad_origen</th>\n",
       "      <th>actividad_destino</th>\n",
       "      <th>estudio_origen_posible</th>\n",
       "      <th>estudio_destino_posible</th>\n",
       "      <th>residencia</th>\n",
       "      <th>renta</th>\n",
       "      <th>edad</th>\n",
       "      <th>sexo</th>\n",
       "      <th>viajes</th>\n",
       "      <th>viajes_km</th>\n",
       "      <th>filename</th>\n",
       "      <th>ingestion_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230508</td>\n",
       "      <td>03</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>2.521</td>\n",
       "      <td>2.703</td>\n",
       "      <td>../data/raw\\\\mitma\\\\20230508_Viajes_distritos....</td>\n",
       "      <td>2025-11-14 16:07:44.032928+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230508</td>\n",
       "      <td>18</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>6.162</td>\n",
       "      <td>7.997</td>\n",
       "      <td>../data/raw\\\\mitma\\\\20230508_Viajes_distritos....</td>\n",
       "      <td>2025-11-14 16:07:44.032928+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230508</td>\n",
       "      <td>19</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>6.162</td>\n",
       "      <td>6.208</td>\n",
       "      <td>../data/raw\\\\mitma\\\\20230508_Viajes_distritos....</td>\n",
       "      <td>2025-11-14 16:07:44.032928+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230508</td>\n",
       "      <td>20</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>9.03</td>\n",
       "      <td>11.528</td>\n",
       "      <td>../data/raw\\\\mitma\\\\20230508_Viajes_distritos....</td>\n",
       "      <td>2025-11-14 16:07:44.032928+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230508</td>\n",
       "      <td>07</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>10-50</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>2.685</td>\n",
       "      <td>30.125</td>\n",
       "      <td>../data/raw\\\\mitma\\\\20230508_Viajes_distritos....</td>\n",
       "      <td>2025-11-14 16:07:44.032928+01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fecha periodo    origen destino distancia actividad_origen  \\\n",
       "0  20230508      03  01009_AM   01001     0.5-2        frecuente   \n",
       "1  20230508      18  01009_AM   01001     0.5-2        frecuente   \n",
       "2  20230508      19  01009_AM   01001     0.5-2        frecuente   \n",
       "3  20230508      20  01009_AM   01001     0.5-2        frecuente   \n",
       "4  20230508      07  01009_AM   01001     10-50        frecuente   \n",
       "\n",
       "  actividad_destino estudio_origen_posible estudio_destino_posible residencia  \\\n",
       "0              casa                     no                      no         01   \n",
       "1              casa                     no                      no         01   \n",
       "2              casa                     no                      no         01   \n",
       "3              casa                     no                      no         01   \n",
       "4              casa                     no                      no         01   \n",
       "\n",
       "  renta edad sexo viajes viajes_km  \\\n",
       "0   <10   NA   NA  2.521     2.703   \n",
       "1   <10   NA   NA  6.162     7.997   \n",
       "2   <10   NA   NA  6.162     6.208   \n",
       "3   <10   NA   NA   9.03    11.528   \n",
       "4   <10   NA   NA  2.685    30.125   \n",
       "\n",
       "                                            filename  \\\n",
       "0  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
       "1  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
       "2  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
       "3  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
       "4  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
       "\n",
       "               ingestion_timestamp  \n",
       "0 2025-11-14 16:07:44.032928+01:00  \n",
       "1 2025-11-14 16:07:44.032928+01:00  \n",
       "2 2025-11-14 16:07:44.032928+01:00  \n",
       "3 2025-11-14 16:07:44.032928+01:00  \n",
       "4 2025-11-14 16:07:44.032928+01:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying the Bronze Schema ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "      <th>null</th>\n",
       "      <th>key</th>\n",
       "      <th>default</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fecha</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>periodo</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>origen</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>destino</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distancia</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actividad_origen</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>actividad_destino</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>estudio_origen_posible</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>estudio_destino_posible</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>residencia</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>renta</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>edad</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sexo</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>viajes</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>viajes_km</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>filename</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ingestion_timestamp</td>\n",
       "      <td>TIMESTAMP WITH TIME ZONE</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                column_name               column_type null   key default extra\n",
       "0                     fecha                   VARCHAR  YES  None    None  None\n",
       "1                   periodo                   VARCHAR  YES  None    None  None\n",
       "2                    origen                   VARCHAR  YES  None    None  None\n",
       "3                   destino                   VARCHAR  YES  None    None  None\n",
       "4                 distancia                   VARCHAR  YES  None    None  None\n",
       "5          actividad_origen                   VARCHAR  YES  None    None  None\n",
       "6         actividad_destino                   VARCHAR  YES  None    None  None\n",
       "7    estudio_origen_posible                   VARCHAR  YES  None    None  None\n",
       "8   estudio_destino_posible                   VARCHAR  YES  None    None  None\n",
       "9                residencia                   VARCHAR  YES  None    None  None\n",
       "10                    renta                   VARCHAR  YES  None    None  None\n",
       "11                     edad                   VARCHAR  YES  None    None  None\n",
       "12                     sexo                   VARCHAR  YES  None    None  None\n",
       "13                   viajes                   VARCHAR  YES  None    None  None\n",
       "14                viajes_km                   VARCHAR  YES  None    None  None\n",
       "15                 filename                   VARCHAR  YES  None    None  None\n",
       "16      ingestion_timestamp  TIMESTAMP WITH TIME ZONE  YES  None    None  None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 4. Verification ---\n",
    "# Let's read back from the new Parquet file to verify it was created correctly.\n",
    "print(\"\\n--- Verifying the Bronze Data ---\")\n",
    "verification_query = f\"SELECT * FROM '{bronze_mobility_path}' LIMIT 5;\"\n",
    "bronze_sample_df = con.execute(verification_query).df()\n",
    "display(bronze_sample_df)\n",
    "\n",
    "print(\"\\n--- Verifying the Bronze Schema ---\")\n",
    "schema_query = f\"DESCRIBE FROM '{bronze_mobility_path}';\"\n",
    "bronze_schema_df = con.execute(schema_query).df()\n",
    "display(bronze_schema_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc244a",
   "metadata": {},
   "source": [
    "### 2.1.2 Supporting MITMA and INE Data into Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2891aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ingested zoning names to: ../data/lakehouse\\bronze\\zoning_districts.parquet\n",
      "✅ Ingested population data to: ../data/lakehouse\\bronze\\population_districts.parquet\n",
      "✅ Ingested INE-MITMA mapping to: ../data/lakehouse\\bronze\\mapping_ine_mitma.parquet\n",
      "✅ Ingested INE GDP data to: ../data/lakehouse\\bronze\\gdp_provinces.parquet\n"
     ]
    }
   ],
   "source": [
    "# --- Ingest nombres_distritos.csv ---\n",
    "source_path = os.path.join(RAW_DATA_PATH, 'mitma', 'nombres_distritos.csv')\n",
    "dest_path = os.path.join(LAKEHOUSE_PATH, 'bronze', 'zoning_districts.parquet')\n",
    "query = f\"COPY (SELECT * FROM read_csv_auto('{source_path}', all_varchar=true)) TO '{dest_path}' (FORMAT PARQUET, OVERWRITE_OR_IGNORE 1);\"\n",
    "con.execute(query)\n",
    "print(f\"✅ Ingested zoning names to: {dest_path}\")\n",
    "\n",
    "# --- Ingest poblacion_distritos.csv ---\n",
    "source_path = os.path.join(RAW_DATA_PATH, 'mitma', 'poblacion_distritos.csv')\n",
    "dest_path = os.path.join(LAKEHOUSE_PATH, 'bronze', 'population_districts.parquet')\n",
    "query = f\"COPY (SELECT * FROM read_csv_auto('{source_path}', all_varchar=true)) TO '{dest_path}' (FORMAT PARQUET, OVERWRITE_OR_IGNORE 1);\"\n",
    "con.execute(query)\n",
    "print(f\"✅ Ingested population data to: {dest_path}\")\n",
    "\n",
    "# --- Ingest relacion_ine_zonificacionMitma.csv ---\n",
    "source_path = os.path.join(RAW_DATA_PATH, 'mitma', 'relacion_ine_zonificacionMitma.csv')\n",
    "dest_path = os.path.join(LAKEHOUSE_PATH, 'bronze', 'mapping_ine_mitma.parquet')\n",
    "query = f\"COPY (SELECT * FROM read_csv_auto('{source_path}', all_varchar=true)) TO '{dest_path}' (FORMAT PARQUET, OVERWRITE_OR_IGNORE 1);\"\n",
    "con.execute(query)\n",
    "print(f\"✅ Ingested INE-MITMA mapping to: {dest_path}\")\n",
    "\n",
    "# --- Ingest INE GDP data --- (semicolon-separated)\n",
    "source_path = os.path.join(RAW_DATA_PATH, 'ine', 'ine_provincial_gdp_2000-2022.csv')\n",
    "dest_path = os.path.join(LAKEHOUSE_PATH, 'bronze', 'gdp_provinces.parquet')\n",
    "query = f\"COPY (SELECT * FROM read_csv_auto('{source_path}', all_varchar=true, sep=';')) TO '{dest_path}' (FORMAT PARQUET, OVERWRITE_OR_IGNORE 1);\"\n",
    "con.execute(query)\n",
    "print(f\"✅ Ingested INE GDP data to: {dest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54c882be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating database schemas (if they don't exist) ---\n",
      "  - Schema 'bronze' is ready.\n",
      "\n",
      "--- Registering Bronze Parquet files as persistent VIEWS in DuckDB ---\n",
      "  - View 'bronze.gdp_provinces' created.\n",
      "  - View 'bronze.mapping_ine_mitma' created.\n",
      "  - View 'bronze.mobility_sample_week' created.\n",
      "  - View 'bronze.population_districts' created.\n",
      "  - View 'bronze.zoning_districts' created.\n",
      "\n",
      "✅ All Bronze files are now visible to external tools under the 'bronze' schema.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# --- 1. Create the 'bronze' schema if it doesn't exist ---\n",
    "# This command creates the \"drawer\" in our database.\n",
    "print(\"--- Creating database schemas (if they don't exist) ---\")\n",
    "con.execute(\"CREATE SCHEMA IF NOT EXISTS bronze;\")\n",
    "print(\"  - Schema 'bronze' is ready.\")\n",
    "\n",
    "# --- 2. Find all the Parquet files ---\n",
    "bronze_files = glob.glob(os.path.join(LAKEHOUSE_PATH, 'bronze', '*.parquet'))\n",
    "\n",
    "# --- 3. Register the files as views INSIDE the new schema ---\n",
    "print(\"\\n--- Registering Bronze Parquet files as persistent VIEWS in DuckDB ---\")\n",
    "for file_path in bronze_files:\n",
    "    # Sanitize the filename to create a valid view name\n",
    "    view_name = os.path.basename(file_path).replace('.parquet', '')\n",
    "    \n",
    "    query = f\"CREATE OR REPLACE VIEW bronze.{view_name} AS SELECT * FROM read_parquet('{file_path}');\"\n",
    "    con.execute(query)\n",
    "    print(f\"  - View 'bronze.{view_name}' created.\")\n",
    "    \n",
    "print(\"\\n✅ All Bronze files are now visible to external tools under the 'bronze' schema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4993a",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.2 Silver layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f43e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating 'silver' schema if it doesn't exist ---\n",
      "  - Schema 'silver' is ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Setup: Create the 'silver' schema ---\n",
    "print(\"--- Creating 'silver' schema if it doesn't exist ---\")\n",
    "con.execute(\"CREATE SCHEMA IF NOT EXISTS silver;\")\n",
    "print(\"  - Schema 'silver' is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a7e945",
   "metadata": {},
   "source": [
    "Cleaned version of mobility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2435675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning mobility data...\n",
      "✓ Cleaning complete!\n",
      "\n",
      "First 5 cleaned rows:\n",
      "   trip_date  hour origin_zone_id destination_zone_id  distance_km  \\\n",
      "0 2023-05-08     3       01009_AM               01001         1.25   \n",
      "1 2023-05-08    18       01009_AM               01001         1.25   \n",
      "2 2023-05-08    19       01009_AM               01001         1.25   \n",
      "3 2023-05-08    20       01009_AM               01001         1.25   \n",
      "4 2023-05-08     7       01009_AM               01001        30.00   \n",
      "\n",
      "   trips_count raw_origin_activity raw_destination_activity  \\\n",
      "0            3           frecuente                     casa   \n",
      "1            6           frecuente                     casa   \n",
      "2            6           frecuente                     casa   \n",
      "3            9           frecuente                     casa   \n",
      "4            3           frecuente                     casa   \n",
      "\n",
      "                                            filename  \\\n",
      "0  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
      "1  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
      "2  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
      "3  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
      "4  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
      "\n",
      "               ingestion_timestamp  \n",
      "0 2025-11-14 16:07:44.032928+01:00  \n",
      "1 2025-11-14 16:07:44.032928+01:00  \n",
      "2 2025-11-14 16:07:44.032928+01:00  \n",
      "3 2025-11-14 16:07:44.032928+01:00  \n",
      "4 2025-11-14 16:07:44.032928+01:00  \n",
      "\n",
      "Data types:\n",
      "                column_name               column_type null   key default extra\n",
      "0                 trip_date                      DATE  YES  None    None  None\n",
      "1                      hour                   INTEGER  YES  None    None  None\n",
      "2            origin_zone_id                   VARCHAR  YES  None    None  None\n",
      "3       destination_zone_id                   VARCHAR  YES  None    None  None\n",
      "4               distance_km                    DOUBLE  YES  None    None  None\n",
      "5               trips_count                   INTEGER  YES  None    None  None\n",
      "6       raw_origin_activity                   VARCHAR  YES  None    None  None\n",
      "7  raw_destination_activity                   VARCHAR  YES  None    None  None\n",
      "8                  filename                   VARCHAR  YES  None    None  None\n",
      "9       ingestion_timestamp  TIMESTAMP WITH TIME ZONE  YES  None    None  None\n"
     ]
    }
   ],
   "source": [
    "# Clean the mobility data\n",
    "print(\"Cleaning mobility data...\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Create cleaned version of mobility data\n",
    "CREATE OR REPLACE TABLE silver.cleaned_mobility AS\n",
    "SELECT\n",
    "    -- Fix dates (convert 20230508 → 2023-05-08)\n",
    "    CAST(\n",
    "        SUBSTR(fecha, 1, 4) || '-' || \n",
    "        SUBSTR(fecha, 5, 2) || '-' || \n",
    "        SUBSTR(fecha, 7, 2) \n",
    "    AS DATE) as trip_date,\n",
    "    \n",
    "    -- Fix hour (ensure it's a number)\n",
    "    CAST(periodo AS INTEGER) as hour,\n",
    "    \n",
    "    -- Clean zone IDs\n",
    "    TRIM(CAST(origen AS VARCHAR)) as origin_zone_id,\n",
    "    TRIM(CAST(destino AS VARCHAR)) as destination_zone_id,\n",
    "    \n",
    "    -- Clean distance (handle messy values)\n",
    "    CASE \n",
    "        WHEN distancia ~ '^[0-9]+\\\\.?[0-9]*$' THEN CAST(distancia AS DOUBLE)  -- Normal numbers\n",
    "        WHEN distancia = '0.5-2' THEN 1.25  -- Specific case: use average\n",
    "        WHEN distancia = '2-10' THEN 6.0    -- Specific case: use average  \n",
    "        WHEN distancia = '10-50' THEN 30.0  -- Specific case: use average\n",
    "        WHEN distancia = '>50' THEN 75.0    -- Specific case: estimate\n",
    "        ELSE NULL  -- Can't convert? Set to NULL\n",
    "    END as distance_km,\n",
    "    \n",
    "    -- Clean trips (ensure it's a number)\n",
    "    CAST(viajes AS INTEGER) as trips_count,\n",
    "    \n",
    "    -- Keep other columns as-is for now\n",
    "    actividad_origen as raw_origin_activity,\n",
    "    actividad_destino as raw_destination_activity,\n",
    "    filename,\n",
    "    ingestion_timestamp\n",
    "\n",
    "FROM bronze.mobility_sample_week\n",
    "WHERE \n",
    "    -- Remove bad records\n",
    "    fecha IS NOT NULL \n",
    "    AND origen IS NOT NULL \n",
    "    AND destino IS NOT NULL \n",
    "    AND viajes IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# STEP 2: Check our results\n",
    "print(\"✓ Cleaning complete!\")\n",
    "print(\"\\nFirst 5 cleaned rows:\")\n",
    "result = con.execute(\"SELECT * FROM silver.cleaned_mobility LIMIT 5\").df()\n",
    "print(result)\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "schema = con.execute(\"DESCRIBE silver.cleaned_mobility\").df()\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d155286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA QUALITY CHECKS ===\n",
      "\n",
      "1. Distance values summary:\n",
      "   total_records  records_with_distance  avg_distance  min_distance  \\\n",
      "0      134726205              134726205     13.968322          1.25   \n",
      "\n",
      "   max_distance  \n",
      "0          75.0  \n",
      "\n",
      "2. Sample of unique zone IDs (check for formatting):\n",
      "  origin_zone_id\n",
      "0          15009\n",
      "1       15047_AM\n",
      "2          15087\n",
      "3        1503003\n",
      "4        1505803\n",
      "5        1508201\n",
      "6        2804902\n",
      "7          15067\n",
      "8          15042\n",
      "9          28022\n",
      "\n",
      "3. Date range:\n",
      "  start_date   end_date\n",
      "0 2023-05-08 2023-05-14\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA QUALITY CHECKS ===\")\n",
    "\n",
    "# Check for any remaining data issues\n",
    "print(\"\\n1. Distance values summary:\")\n",
    "dist_check = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_records,\n",
    "        COUNT(distance_km) as records_with_distance,\n",
    "        AVG(distance_km) as avg_distance,\n",
    "        MIN(distance_km) as min_distance,\n",
    "        MAX(distance_km) as max_distance\n",
    "    FROM silver.cleaned_mobility\n",
    "\"\"\").df()\n",
    "print(dist_check)\n",
    "\n",
    "print(\"\\n2. Sample of unique zone IDs (check for formatting):\")\n",
    "zones_check = con.execute(\"\"\"\n",
    "    SELECT DISTINCT origin_zone_id \n",
    "    FROM silver.cleaned_mobility \n",
    "    LIMIT 10\n",
    "\"\"\").df()\n",
    "print(zones_check)\n",
    "\n",
    "print(\"\\n3. Date range:\")\n",
    "date_range = con.execute(\"\"\"\n",
    "    SELECT MIN(trip_date) as start_date, MAX(trip_date) as end_date \n",
    "    FROM silver.cleaned_mobility\n",
    "\"\"\").df()\n",
    "print(date_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b82685",
   "metadata": {},
   "source": [
    "Clean Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7c16a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning population data...\n",
      "\n",
      "Sample of raw population data:\n",
      "    column0  column1\n",
      "0     01001   2925.0\n",
      "1     01002  10307.0\n",
      "2  01004_AM   3005.0\n",
      "3  01009_AM   4599.0\n",
      "4     01010   2951.0\n",
      "\n",
      "Column names in population data:\n",
      "   cid     name     type  notnull dflt_value     pk\n",
      "0    0  column0  VARCHAR    False       None  False\n",
      "1    1  column1  VARCHAR    False       None  False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Cleaning population data...\")\n",
    "\n",
    "# First, let's check what the raw population data looks like\n",
    "print(\"\\nSample of raw population data:\")\n",
    "pop_sample = con.execute(\"SELECT * FROM bronze.population_districts LIMIT 5\").df()\n",
    "print(pop_sample)\n",
    "\n",
    "print(\"\\nColumn names in population data:\")\n",
    "pop_columns = con.execute(\"PRAGMA table_info(bronze.population_districts)\").df()\n",
    "print(pop_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef82e9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning population data...\n",
      "✓ Population data cleaned!\n",
      "\n",
      "First 5 cleaned population rows:\n",
      "    zone_id  population_count\n",
      "0     01001              2925\n",
      "1     01002             10307\n",
      "2  01004_AM              3005\n",
      "3  01009_AM              4599\n",
      "4     01010              2951\n",
      "\n",
      "Data types:\n",
      "        column_name column_type null   key default extra\n",
      "0           zone_id     VARCHAR  YES  None    None  None\n",
      "1  population_count     INTEGER  YES  None    None  None\n",
      "\n",
      "Population data quality summary:\n",
      "   total_records  records_with_population  records_with_null_population  \\\n",
      "0           3792                     3743                            49   \n",
      "\n",
      "   avg_population  \n",
      "0    12659.659898  \n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning population data...\")\n",
    "\n",
    "# Create cleaned population table\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE silver.cleaned_population AS\n",
    "SELECT\n",
    "    -- Clean zone IDs (remove any whitespace)\n",
    "    TRIM(CAST(column0 AS VARCHAR)) as zone_id,\n",
    "    \n",
    "    -- Clean population count (handle 'NA' values and convert to integer)\n",
    "    CASE \n",
    "        WHEN column1 = 'NA' THEN NULL\n",
    "        WHEN TRIM(column1) = '' THEN NULL\n",
    "        ELSE CAST(CAST(column1 AS DOUBLE) AS INTEGER)\n",
    "    END as population_count\n",
    "\n",
    "FROM bronze.population_districts\n",
    "WHERE \n",
    "    -- Remove records with missing zone IDs\n",
    "    column0 IS NOT NULL \n",
    "    AND column1 IS NOT NULL\n",
    "    AND TRIM(column0) != ''  -- Remove empty zone IDs\n",
    "\"\"\")\n",
    "\n",
    "# Verify the results\n",
    "print(\"✓ Population data cleaned!\")\n",
    "print(\"\\nFirst 5 cleaned population rows:\")\n",
    "result = con.execute(\"SELECT * FROM silver.cleaned_population LIMIT 5\").df()\n",
    "print(result)\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "schema = con.execute(\"DESCRIBE silver.cleaned_population\").df()\n",
    "print(schema)\n",
    "\n",
    "print(\"\\nPopulation data quality summary:\")\n",
    "quality_check = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_records,\n",
    "        COUNT(population_count) as records_with_population,\n",
    "        COUNT(*) - COUNT(population_count) as records_with_null_population,\n",
    "        AVG(population_count) as avg_population\n",
    "    FROM silver.cleaned_population\n",
    "\"\"\").df()\n",
    "print(quality_check)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6bc879",
   "metadata": {},
   "source": [
    "Combine cleaned tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f494c07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating integrated OD table with demographics...\n",
      "✓ Integrated table created!\n",
      "\n",
      "First 5 rows of integrated data:\n",
      "   trip_date  hour origin_zone_id destination_zone_id  distance_km  \\\n",
      "0 2023-05-08     3       01009_AM               01001         1.25   \n",
      "1 2023-05-08    18       01009_AM               01001         1.25   \n",
      "2 2023-05-08    19       01009_AM               01001         1.25   \n",
      "3 2023-05-08    20       01009_AM               01001         1.25   \n",
      "4 2023-05-08     7       01009_AM               01001        30.00   \n",
      "\n",
      "   trips_count  origin_population  destination_population raw_origin_activity  \\\n",
      "0            3               4599                    2925           frecuente   \n",
      "1            6               4599                    2925           frecuente   \n",
      "2            6               4599                    2925           frecuente   \n",
      "3            9               4599                    2925           frecuente   \n",
      "4            3               4599                    2925           frecuente   \n",
      "\n",
      "  raw_destination_activity                                           filename  \n",
      "0                     casa  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....  \n",
      "1                     casa  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....  \n",
      "2                     casa  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....  \n",
      "3                     casa  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....  \n",
      "4                     casa  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....  \n",
      "\n",
      "Join quality check:\n",
      "   total_trips  trips_with_origin_population  \\\n",
      "0    134726205                     134402517   \n",
      "\n",
      "   trips_with_destination_population  \n",
      "0                          134401830  \n"
     ]
    }
   ],
   "source": [
    "print(\"Creating integrated OD table with demographics...\")\n",
    "\n",
    "# Create the integrated table by joining mobility and population data\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE silver.silver_integrated_od AS\n",
    "SELECT\n",
    "    -- Mobility data\n",
    "    m.trip_date,\n",
    "    m.hour,\n",
    "    m.origin_zone_id,\n",
    "    m.destination_zone_id,\n",
    "    m.distance_km,\n",
    "    m.trips_count,\n",
    "    \n",
    "    -- Population data for ORIGIN zone\n",
    "    orig_pop.population_count as origin_population,\n",
    "    \n",
    "    -- Population data for DESTINATION zone  \n",
    "    dest_pop.population_count as destination_population,\n",
    "    \n",
    "    -- Keep raw values for reference\n",
    "    m.raw_origin_activity,\n",
    "    m.raw_destination_activity,\n",
    "    m.filename\n",
    "\n",
    "FROM silver.cleaned_mobility m\n",
    "LEFT JOIN silver.cleaned_population orig_pop \n",
    "    ON m.origin_zone_id = orig_pop.zone_id\n",
    "LEFT JOIN silver.cleaned_population dest_pop \n",
    "    ON m.destination_zone_id = dest_pop.zone_id\n",
    "\"\"\")\n",
    "\n",
    "# Verify the results\n",
    "print(\"✓ Integrated table created!\")\n",
    "print(\"\\nFirst 5 rows of integrated data:\")\n",
    "result = con.execute(\"SELECT * FROM silver.silver_integrated_od LIMIT 5\").df()\n",
    "print(result)\n",
    "\n",
    "print(\"\\nJoin quality check:\")\n",
    "join_quality = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_trips,\n",
    "        COUNT(origin_population) as trips_with_origin_population,\n",
    "        COUNT(destination_population) as trips_with_destination_population\n",
    "    FROM silver.silver_integrated_od\n",
    "\"\"\").df()\n",
    "print(join_quality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f297a44",
   "metadata": {},
   "source": [
    "Create parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04097d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting Silver tables to Parquet files...\n",
      "✓ Exported silver.cleaned_mobility to ../data/lakehouse/silver/cleaned_mobility.parquet\n",
      "✓ Exported silver.cleaned_population to ../data/lakehouse/silver/cleaned_population.parquet\n",
      "✓ Exported silver.silver_integrated_od to ../data/lakehouse/silver/silver_integrated_od.parquet\n",
      "\n",
      "Checking created Parquet files:\n"
     ]
    }
   ],
   "source": [
    "# Ensure silver directory exists\n",
    "os.makedirs('data/lakehouse/silver', exist_ok=True)\n",
    "\n",
    "print(\"Exporting Silver tables to Parquet files...\")\n",
    "\n",
    "# Export each table to Parquet\n",
    "tables = ['cleaned_mobility', 'cleaned_population', 'silver_integrated_od']\n",
    "\n",
    "for table in tables:\n",
    "    parquet_path = f'../data/lakehouse/silver/{table}.parquet'\n",
    "    con.execute(f\"\"\"\n",
    "    COPY silver.{table} \n",
    "    TO '{parquet_path}' \n",
    "    (FORMAT PARQUET)\n",
    "    \"\"\")\n",
    "    print(f\"✓ Exported silver.{table} to {parquet_path}\")\n",
    "\n",
    "# Verify the files were created\n",
    "print(\"\\nChecking created Parquet files:\")\n",
    "import glob\n",
    "parquet_files = glob.glob('../data/lakehouse/silver/*.parquet')\n",
    "for file in parquet_files:\n",
    "    file_size = os.path.getsize(file) / (1024*1024)\n",
    "    print(f\"  - {os.path.basename(file)} ({file_size:.2f} MB)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc997ac",
   "metadata": {},
   "source": [
    "Final check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fef8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SILVER LAYER COMPLETION CHECK ===\n",
      "1. Tables in silver schema:\n",
      "                   name\n",
      "0      cleaned_mobility\n",
      "1    cleaned_population\n",
      "2  silver_integrated_od\n",
      "\n",
      "2. Parquet files in ../data/lakehouse/silver/:\n",
      "   - cleaned_mobility.parquet (275.3 MB)\n",
      "   - cleaned_population.parquet (0.0 MB)\n",
      "   - silver_integrated_od.parquet (372.7 MB)\n",
      "\n",
      "3. Data consistency check:\n",
      "   - cleaned_mobility: 134,726,205 records\n",
      "   - cleaned_population: 3,792 records\n",
      "   - silver_integrated_od: 134,726,205 records\n"
     ]
    }
   ],
   "source": [
    "print(\"=== SILVER LAYER COMPLETION CHECK ===\")\n",
    "\n",
    "# Check tables exist\n",
    "print(\"1. Tables in silver schema:\")\n",
    "tables = con.execute(\"SHOW TABLES FROM silver\").df()\n",
    "print(tables)\n",
    "\n",
    "# Check Parquet files exist\n",
    "print(\"\\n2. Parquet files in ../data/lakehouse/silver/:\")\n",
    "parquet_files = glob.glob('../data/lakehouse/silver/*.parquet')\n",
    "for file in parquet_files:\n",
    "    size_mb = os.path.getsize(file) / (1024*1024)\n",
    "    print(f\"   - {os.path.basename(file)} ({size_mb:.1f} MB)\")\n",
    "\n",
    "# Verify record counts match\n",
    "print(\"\\n3. Data consistency check:\")\n",
    "for table in ['cleaned_mobility', 'cleaned_population', 'silver_integrated_od']:\n",
    "    count = con.execute(f\"SELECT COUNT(*) as count FROM silver.{table}\").df()\n",
    "    print(f\"   - {table}: {count.iloc[0]['count']:,} records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

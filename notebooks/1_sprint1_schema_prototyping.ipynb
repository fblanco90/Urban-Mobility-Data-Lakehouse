{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaef76e8",
   "metadata": {},
   "source": [
    "# Sprint 1: Schema Design and Prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c59b5d3",
   "metadata": {},
   "source": [
    "#### Initial configuration and conection to duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22aa272f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB is now connected to the persistent database file at:\n",
      "-> ../data/lakehouse\\lakehouse.duckdb\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- Configuration ---\n",
    "# Define paths to your raw data and the future lakehouse layers\n",
    "RAW_DATA_PATH = '../data/raw'\n",
    "LAKEHOUSE_PATH = '../data/lakehouse'\n",
    "LAKEHOUSE_DB_PATH = os.path.join(LAKEHOUSE_PATH, 'lakehouse.duckdb')\n",
    "\n",
    "# Create the lakehouse directories if they don't exist\n",
    "os.makedirs(os.path.join(LAKEHOUSE_PATH, 'bronze'), exist_ok=True)\n",
    "os.makedirs(os.path.join(LAKEHOUSE_PATH, 'silver'), exist_ok=True)\n",
    "os.makedirs(os.path.join(LAKEHOUSE_PATH, 'gold'), exist_ok=True)\n",
    "\n",
    "# --- DuckDB Connection ---\n",
    "con = duckdb.connect(database=LAKEHOUSE_DB_PATH, read_only=False)\n",
    "\n",
    "print(f\"DuckDB is now connected to the persistent database file at:\")\n",
    "print(f\"-> {LAKEHOUSE_DB_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be6104",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Step 1: Data Exploration\n",
    "\n",
    "\n",
    "## 1. Data Exploration: Inspecting the Raw Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e567a",
   "metadata": {},
   "source": [
    "#### Explore a MITMA Mobility File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91dc8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample of Mobility Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>periodo</th>\n",
       "      <th>origen</th>\n",
       "      <th>destino</th>\n",
       "      <th>distancia</th>\n",
       "      <th>actividad_origen</th>\n",
       "      <th>actividad_destino</th>\n",
       "      <th>estudio_origen_posible</th>\n",
       "      <th>estudio_destino_posible</th>\n",
       "      <th>residencia</th>\n",
       "      <th>renta</th>\n",
       "      <th>edad</th>\n",
       "      <th>sexo</th>\n",
       "      <th>viajes</th>\n",
       "      <th>viajes_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230508</td>\n",
       "      <td>03</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>2.521</td>\n",
       "      <td>2.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230508</td>\n",
       "      <td>18</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>6.162</td>\n",
       "      <td>7.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230508</td>\n",
       "      <td>19</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>6.162</td>\n",
       "      <td>6.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230508</td>\n",
       "      <td>20</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>9.030</td>\n",
       "      <td>11.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230508</td>\n",
       "      <td>07</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>10-50</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>2.685</td>\n",
       "      <td>30.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fecha periodo    origen destino distancia actividad_origen  \\\n",
       "0  20230508      03  01009_AM   01001     0.5-2        frecuente   \n",
       "1  20230508      18  01009_AM   01001     0.5-2        frecuente   \n",
       "2  20230508      19  01009_AM   01001     0.5-2        frecuente   \n",
       "3  20230508      20  01009_AM   01001     0.5-2        frecuente   \n",
       "4  20230508      07  01009_AM   01001     10-50        frecuente   \n",
       "\n",
       "  actividad_destino estudio_origen_posible  estudio_destino_posible  \\\n",
       "0              casa                     no                    False   \n",
       "1              casa                     no                    False   \n",
       "2              casa                     no                    False   \n",
       "3              casa                     no                    False   \n",
       "4              casa                     no                    False   \n",
       "\n",
       "  residencia renta edad sexo  viajes  viajes_km  \n",
       "0         01   <10   NA   NA   2.521      2.703  \n",
       "1         01   <10   NA   NA   6.162      7.997  \n",
       "2         01   <10   NA   NA   6.162      6.208  \n",
       "3         01   <10   NA   NA   9.030     11.528  \n",
       "4         01   <10   NA   NA   2.685     30.125  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Schema of Mobility Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "      <th>null</th>\n",
       "      <th>key</th>\n",
       "      <th>default</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fecha</td>\n",
       "      <td>BIGINT</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>periodo</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>origen</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>destino</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distancia</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actividad_origen</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>actividad_destino</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>estudio_origen_posible</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>estudio_destino_posible</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>residencia</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>renta</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>edad</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sexo</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>viajes</td>\n",
       "      <td>DOUBLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>viajes_km</td>\n",
       "      <td>DOUBLE</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                column_name column_type null   key default extra\n",
       "0                     fecha      BIGINT  YES  None    None  None\n",
       "1                   periodo     VARCHAR  YES  None    None  None\n",
       "2                    origen     VARCHAR  YES  None    None  None\n",
       "3                   destino     VARCHAR  YES  None    None  None\n",
       "4                 distancia     VARCHAR  YES  None    None  None\n",
       "5          actividad_origen     VARCHAR  YES  None    None  None\n",
       "6         actividad_destino     VARCHAR  YES  None    None  None\n",
       "7    estudio_origen_posible     VARCHAR  YES  None    None  None\n",
       "8   estudio_destino_posible     BOOLEAN  YES  None    None  None\n",
       "9                residencia     VARCHAR  YES  None    None  None\n",
       "10                    renta     VARCHAR  YES  None    None  None\n",
       "11                     edad     VARCHAR  YES  None    None  None\n",
       "12                     sexo     VARCHAR  YES  None    None  None\n",
       "13                   viajes      DOUBLE  YES  None    None  None\n",
       "14                viajes_km      DOUBLE  YES  None    None  None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path to one of the daily mobility files\n",
    "mobility_file_path = os.path.join(RAW_DATA_PATH, 'mitma', '20230508_Viajes_distritos.csv.gz')\n",
    "\n",
    "# Use DuckDB to directly read and describe the gzipped CSV\n",
    "# The 'read_csv_auto' function is powerful and can infer types, headers, etc.\n",
    "query = f\"\"\"--sql\n",
    "    SELECT *\n",
    "    FROM read_csv_auto('{mobility_file_path}')\n",
    "    LIMIT 5;\n",
    "\"\"\"\n",
    "df_mobility_sample = con.execute(query).df()\n",
    "\n",
    "print(\"--- Sample of Mobility Data ---\")\n",
    "display(df_mobility_sample)\n",
    "\n",
    "print(\"\\n--- Schema of Mobility Data ---\")\n",
    "# Let's get the column names and data types as inferred by DuckDB\n",
    "query_desc = f\"DESCRIBE SELECT * FROM read_csv_auto('{mobility_file_path}');\"\n",
    "df_mobility_schema = con.execute(query_desc).df()\n",
    "display(df_mobility_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b476d0d",
   "metadata": {},
   "source": [
    "#### Explore the MITMA Zoning File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fd8b76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample of Zoning Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>Alegría-Dulantzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01002</td>\n",
       "      <td>Amurrio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01004_AM</td>\n",
       "      <td>Artziniega agregacion de municipios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01009_AM</td>\n",
       "      <td>Asparrena agregacion de municipios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01010</td>\n",
       "      <td>Ayala/Aiara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                 name\n",
       "0     01001                     Alegría-Dulantzi\n",
       "1     01002                              Amurrio\n",
       "2  01004_AM  Artziniega agregacion de municipios\n",
       "3  01009_AM   Asparrena agregacion de municipios\n",
       "4     01010                          Ayala/Aiara"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Schema of Zoning Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "      <th>null</th>\n",
       "      <th>key</th>\n",
       "      <th>default</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  column_name column_type null   key default extra\n",
       "0          ID     VARCHAR  YES  None    None  None\n",
       "1        name     VARCHAR  YES  None    None  None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path to the district names file\n",
    "zoning_file_path = os.path.join(RAW_DATA_PATH, 'mitma', 'nombres_distritos.csv')\n",
    "\n",
    "# Load and inspect the zoning file\n",
    "query = f\"\"\"--sql\n",
    "    SELECT *\n",
    "    FROM read_csv_auto('{zoning_file_path}')\n",
    "    LIMIT 5;\n",
    "\"\"\"\n",
    "df_zoning_sample = con.execute(query).df()\n",
    "\n",
    "print(\"--- Sample of Zoning Data ---\")\n",
    "display(df_zoning_sample)\n",
    "\n",
    "print(\"\\n--- Schema of Zoning Data ---\")\n",
    "query_desc = f\"DESCRIBE SELECT * FROM read_csv_auto('{zoning_file_path}');\"\n",
    "df_zoning_schema = con.execute(query_desc).df()\n",
    "display(df_zoning_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab40d70",
   "metadata": {},
   "source": [
    "#### Explore the INE Economic File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc9f995a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample of INE Economic Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Municipios</th>\n",
       "      <th>Distritos</th>\n",
       "      <th>Secciones</th>\n",
       "      <th>Indicadores de renta media</th>\n",
       "      <th>Periodo</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001 Alegría-Dulantzi</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Renta neta media por persona</td>\n",
       "      <td>2023</td>\n",
       "      <td>16.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01001 Alegría-Dulantzi</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Renta neta media por persona</td>\n",
       "      <td>2022</td>\n",
       "      <td>15.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01001 Alegría-Dulantzi</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Renta neta media por persona</td>\n",
       "      <td>2021</td>\n",
       "      <td>14.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01001 Alegría-Dulantzi</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Renta neta media por persona</td>\n",
       "      <td>2020</td>\n",
       "      <td>13.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01001 Alegría-Dulantzi</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Renta neta media por persona</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Municipios Distritos Secciones    Indicadores de renta media  \\\n",
       "0  01001 Alegría-Dulantzi      None      None  Renta neta media por persona   \n",
       "1  01001 Alegría-Dulantzi      None      None  Renta neta media por persona   \n",
       "2  01001 Alegría-Dulantzi      None      None  Renta neta media por persona   \n",
       "3  01001 Alegría-Dulantzi      None      None  Renta neta media por persona   \n",
       "4  01001 Alegría-Dulantzi      None      None  Renta neta media por persona   \n",
       "\n",
       "   Periodo   Total  \n",
       "0     2023  16.429  \n",
       "1     2022  15.116  \n",
       "2     2021  14.647  \n",
       "3     2020  13.969  \n",
       "4     2019  14.299  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path to the INE GDP file\n",
    "ine_file_path = os.path.join(RAW_DATA_PATH, 'ine', 'ine_renta_municipios.csv') # Or whatever you named it\n",
    "\n",
    "# This file is semicolon-separated, so we tell DuckDB explicitly\n",
    "query = f\"\"\"--sql\n",
    "    SELECT *\n",
    "    FROM read_csv_auto('{ine_file_path}', sep=';')\n",
    "    LIMIT 5;\n",
    "\"\"\"\n",
    "df_ine_sample = con.execute(query).df()\n",
    "\n",
    "print(\"--- Sample of INE Economic Data ---\")\n",
    "display(df_ine_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff111fef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Step 2: Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca75740",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.1 Bronze ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebe7d7",
   "metadata": {},
   "source": [
    "#### 2.1.1 Mobility files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5805c395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following mobility files to ingest:\n",
      " - 20230508_Viajes_distritos.csv.gz\n",
      " - 20230509_Viajes_distritos.csv.gz\n",
      " - 20230510_Viajes_distritos.csv.gz\n",
      " - 20230511_Viajes_distritos.csv.gz\n",
      " - 20230512_Viajes_distritos.csv.gz\n",
      " - 20230513_Viajes_distritos.csv.gz\n",
      " - 20230514_Viajes_distritos.csv.gz\n",
      "\n",
      "✅ Successfully ingested 7 files into a single Bronze Parquet file:\n",
      "   -> ../data/lakehouse\\bronze\\semana_movilidad.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. Define File Paths ---\n",
    "# Source: All gzipped CSV files for the week in the raw/mitma directory\n",
    "mitma_raw_glob_path = os.path.join(RAW_DATA_PATH, 'mitma', '*_Viajes_distritos.csv.gz')\n",
    "# Destination: A single Parquet file in the bronze layer\n",
    "bronze_mobility_path = os.path.join(LAKEHOUSE_PATH, 'bronze', 'semana_movilidad.parquet')\n",
    "\n",
    "# --- 2. Find all the raw mobility files ---\n",
    "mobility_files = glob.glob(mitma_raw_glob_path)\n",
    "# It's good practice to print the files you've found to ensure it's working\n",
    "print(\"Found the following mobility files to ingest:\")\n",
    "for f in mobility_files:\n",
    "    print(f\" - {os.path.basename(f)}\")\n",
    "\n",
    "# --- 3. Construct and Execute the Ingestion Query ---\n",
    "# The query reads all CSVs at once, adds metadata, and copies the result to a Parquet file.\n",
    "# DuckDB's read_csv_auto can take a list of files.\n",
    "# We also use 'filename=true' to automatically add a column with the source filename.\n",
    "ingestion_query = f\"\"\"--sql\n",
    "    COPY (\n",
    "        SELECT \n",
    "            *,\n",
    "            CURRENT_TIMESTAMP AS ingestion_timestamp\n",
    "        FROM read_csv_auto({mobility_files}, filename=true, all_varchar=true) -- <--- THIS IS THE FIX\n",
    "    ) TO '{bronze_mobility_path}' (FORMAT PARQUET, OVERWRITE_OR_IGNORE 1);\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "con.execute(ingestion_query)\n",
    "\n",
    "print(f\"\\n✅ Successfully ingested {len(mobility_files)} files into a single Bronze Parquet file:\")\n",
    "print(f\"   -> {bronze_mobility_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe05e80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying the Bronze Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>periodo</th>\n",
       "      <th>origen</th>\n",
       "      <th>destino</th>\n",
       "      <th>distancia</th>\n",
       "      <th>actividad_origen</th>\n",
       "      <th>actividad_destino</th>\n",
       "      <th>estudio_origen_posible</th>\n",
       "      <th>estudio_destino_posible</th>\n",
       "      <th>residencia</th>\n",
       "      <th>renta</th>\n",
       "      <th>edad</th>\n",
       "      <th>sexo</th>\n",
       "      <th>viajes</th>\n",
       "      <th>viajes_km</th>\n",
       "      <th>filename</th>\n",
       "      <th>ingestion_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230508</td>\n",
       "      <td>03</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>2.521</td>\n",
       "      <td>2.703</td>\n",
       "      <td>../data/raw\\\\mitma\\\\20230508_Viajes_distritos....</td>\n",
       "      <td>2025-11-16 12:29:39.357110+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230508</td>\n",
       "      <td>18</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>6.162</td>\n",
       "      <td>7.997</td>\n",
       "      <td>../data/raw\\\\mitma\\\\20230508_Viajes_distritos....</td>\n",
       "      <td>2025-11-16 12:29:39.357110+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230508</td>\n",
       "      <td>19</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>6.162</td>\n",
       "      <td>6.208</td>\n",
       "      <td>../data/raw\\\\mitma\\\\20230508_Viajes_distritos....</td>\n",
       "      <td>2025-11-16 12:29:39.357110+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230508</td>\n",
       "      <td>20</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>0.5-2</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>9.03</td>\n",
       "      <td>11.528</td>\n",
       "      <td>../data/raw\\\\mitma\\\\20230508_Viajes_distritos....</td>\n",
       "      <td>2025-11-16 12:29:39.357110+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230508</td>\n",
       "      <td>07</td>\n",
       "      <td>01009_AM</td>\n",
       "      <td>01001</td>\n",
       "      <td>10-50</td>\n",
       "      <td>frecuente</td>\n",
       "      <td>casa</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>01</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>2.685</td>\n",
       "      <td>30.125</td>\n",
       "      <td>../data/raw\\\\mitma\\\\20230508_Viajes_distritos....</td>\n",
       "      <td>2025-11-16 12:29:39.357110+01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fecha periodo    origen destino distancia actividad_origen  \\\n",
       "0  20230508      03  01009_AM   01001     0.5-2        frecuente   \n",
       "1  20230508      18  01009_AM   01001     0.5-2        frecuente   \n",
       "2  20230508      19  01009_AM   01001     0.5-2        frecuente   \n",
       "3  20230508      20  01009_AM   01001     0.5-2        frecuente   \n",
       "4  20230508      07  01009_AM   01001     10-50        frecuente   \n",
       "\n",
       "  actividad_destino estudio_origen_posible estudio_destino_posible residencia  \\\n",
       "0              casa                     no                      no         01   \n",
       "1              casa                     no                      no         01   \n",
       "2              casa                     no                      no         01   \n",
       "3              casa                     no                      no         01   \n",
       "4              casa                     no                      no         01   \n",
       "\n",
       "  renta edad sexo viajes viajes_km  \\\n",
       "0   <10   NA   NA  2.521     2.703   \n",
       "1   <10   NA   NA  6.162     7.997   \n",
       "2   <10   NA   NA  6.162     6.208   \n",
       "3   <10   NA   NA   9.03    11.528   \n",
       "4   <10   NA   NA  2.685    30.125   \n",
       "\n",
       "                                            filename  \\\n",
       "0  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
       "1  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
       "2  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
       "3  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
       "4  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
       "\n",
       "               ingestion_timestamp  \n",
       "0 2025-11-16 12:29:39.357110+01:00  \n",
       "1 2025-11-16 12:29:39.357110+01:00  \n",
       "2 2025-11-16 12:29:39.357110+01:00  \n",
       "3 2025-11-16 12:29:39.357110+01:00  \n",
       "4 2025-11-16 12:29:39.357110+01:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying the Bronze Schema ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "      <th>null</th>\n",
       "      <th>key</th>\n",
       "      <th>default</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fecha</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>periodo</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>origen</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>destino</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distancia</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>actividad_origen</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>actividad_destino</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>estudio_origen_posible</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>estudio_destino_posible</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>residencia</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>renta</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>edad</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sexo</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>viajes</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>viajes_km</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>filename</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ingestion_timestamp</td>\n",
       "      <td>TIMESTAMP WITH TIME ZONE</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                column_name               column_type null   key default extra\n",
       "0                     fecha                   VARCHAR  YES  None    None  None\n",
       "1                   periodo                   VARCHAR  YES  None    None  None\n",
       "2                    origen                   VARCHAR  YES  None    None  None\n",
       "3                   destino                   VARCHAR  YES  None    None  None\n",
       "4                 distancia                   VARCHAR  YES  None    None  None\n",
       "5          actividad_origen                   VARCHAR  YES  None    None  None\n",
       "6         actividad_destino                   VARCHAR  YES  None    None  None\n",
       "7    estudio_origen_posible                   VARCHAR  YES  None    None  None\n",
       "8   estudio_destino_posible                   VARCHAR  YES  None    None  None\n",
       "9                residencia                   VARCHAR  YES  None    None  None\n",
       "10                    renta                   VARCHAR  YES  None    None  None\n",
       "11                     edad                   VARCHAR  YES  None    None  None\n",
       "12                     sexo                   VARCHAR  YES  None    None  None\n",
       "13                   viajes                   VARCHAR  YES  None    None  None\n",
       "14                viajes_km                   VARCHAR  YES  None    None  None\n",
       "15                 filename                   VARCHAR  YES  None    None  None\n",
       "16      ingestion_timestamp  TIMESTAMP WITH TIME ZONE  YES  None    None  None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 4. Verification ---\n",
    "# Let's read back from the new Parquet file to verify it was created correctly.\n",
    "print(\"\\n--- Verifying the Bronze Data ---\")\n",
    "verification_query = f\"SELECT * FROM '{bronze_mobility_path}' LIMIT 5;\"\n",
    "bronze_sample_df = con.execute(verification_query).df()\n",
    "display(bronze_sample_df)\n",
    "\n",
    "print(\"\\n--- Verifying the Bronze Schema ---\")\n",
    "schema_query = f\"DESCRIBE FROM '{bronze_mobility_path}';\"\n",
    "bronze_schema_df = con.execute(schema_query).df()\n",
    "display(bronze_schema_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc244a",
   "metadata": {},
   "source": [
    "### 2.1.2 Supporting MITMA and INE Data into Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2891aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ingested zoning names to: ../data/lakehouse\\bronze\\nombres_distritos.parquet\n",
      "✅ Ingested population data to: ../data/lakehouse\\bronze\\poblacion_distritos.parquet\n",
      "✅ Ingested INE-MITMA mapping to: ../data/lakehouse\\bronze\\relacion_ine_zonificacionMitma.parquet\n",
      "✅ Ingested INE GDP data to: ../data/lakehouse\\bronze\\ine_renta_municipios.parquet\n"
     ]
    }
   ],
   "source": [
    "# --- Ingest nombres_distritos.csv ---\n",
    "source_path = os.path.join(RAW_DATA_PATH, 'mitma', 'nombres_distritos.csv')\n",
    "dest_path = os.path.join(LAKEHOUSE_PATH, 'bronze', 'nombres_distritos.parquet')\n",
    "query = f\"COPY (SELECT * FROM read_csv_auto('{source_path}', all_varchar=true)) TO '{dest_path}' (FORMAT PARQUET, OVERWRITE_OR_IGNORE 1);\"\n",
    "con.execute(query)\n",
    "print(f\"✅ Ingested zoning names to: {dest_path}\")\n",
    "\n",
    "# --- Ingest poblacion_distritos.csv ---\n",
    "source_path = os.path.join(RAW_DATA_PATH, 'mitma', 'poblacion_distritos.csv')\n",
    "dest_path = os.path.join(LAKEHOUSE_PATH, 'bronze', 'poblacion_distritos.parquet')\n",
    "query = f\"COPY (SELECT * FROM read_csv_auto('{source_path}', all_varchar=true)) TO '{dest_path}' (FORMAT PARQUET, OVERWRITE_OR_IGNORE 1);\"\n",
    "con.execute(query)\n",
    "print(f\"✅ Ingested population data to: {dest_path}\")\n",
    "\n",
    "# --- Ingest relacion_ine_zonificacionMitma.csv ---\n",
    "source_path = os.path.join(RAW_DATA_PATH, 'mitma', 'relacion_ine_zonificacionMitma.csv')\n",
    "dest_path = os.path.join(LAKEHOUSE_PATH, 'bronze', 'relacion_ine_zonificacionMitma.parquet')\n",
    "query = f\"COPY (SELECT * FROM read_csv_auto('{source_path}', all_varchar=true)) TO '{dest_path}' (FORMAT PARQUET, OVERWRITE_OR_IGNORE 1);\"\n",
    "con.execute(query)\n",
    "print(f\"✅ Ingested INE-MITMA mapping to: {dest_path}\")\n",
    "\n",
    "# --- Ingest INE GDP data --- (semicolon-separated)\n",
    "source_path = os.path.join(RAW_DATA_PATH, 'ine', 'ine_renta_municipios.csv')\n",
    "dest_path = os.path.join(LAKEHOUSE_PATH, 'bronze', 'ine_renta_municipios.parquet')\n",
    "query = f\"COPY (SELECT * FROM read_csv_auto('{source_path}', all_varchar=true, sep=';')) TO '{dest_path}' (FORMAT PARQUET, OVERWRITE_OR_IGNORE 1);\"\n",
    "con.execute(query)\n",
    "print(f\"✅ Ingested INE GDP data to: {dest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54c882be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating database schemas (if they don't exist) ---\n",
      "  - Schema 'bronze' is ready.\n",
      "\n",
      "--- Registering Bronze Parquet files as persistent VIEWS in DuckDB ---\n",
      "  - View 'bronze.ine_renta_municipios' created.\n",
      "  - View 'bronze.nombres_distritos' created.\n",
      "  - View 'bronze.poblacion_distritos' created.\n",
      "  - View 'bronze.relacion_ine_zonificacionMitma' created.\n",
      "  - View 'bronze.semana_movilidad' created.\n",
      "\n",
      "✅ All Bronze files are now visible to external tools under the 'bronze' schema.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# --- 1. Create the 'bronze' schema if it doesn't exist ---\n",
    "# This command creates the \"drawer\" in our database.\n",
    "print(\"--- Creating database schemas (if they don't exist) ---\")\n",
    "con.execute(\"CREATE SCHEMA IF NOT EXISTS bronze;\")\n",
    "print(\"  - Schema 'bronze' is ready.\")\n",
    "\n",
    "# --- 2. Find all the Parquet files ---\n",
    "bronze_files = glob.glob(os.path.join(LAKEHOUSE_PATH, 'bronze', '*.parquet'))\n",
    "\n",
    "# --- 3. Register the files as views INSIDE the new schema ---\n",
    "print(\"\\n--- Registering Bronze Parquet files as persistent VIEWS in DuckDB ---\")\n",
    "for file_path in bronze_files:\n",
    "    # Sanitize the filename to create a valid view name\n",
    "    view_name = os.path.basename(file_path).replace('.parquet', '')\n",
    "    \n",
    "    query = f\"CREATE OR REPLACE VIEW bronze.{view_name} AS SELECT * FROM read_parquet('{file_path}');\"\n",
    "    con.execute(query)\n",
    "    print(f\"  - View 'bronze.{view_name}' created.\")\n",
    "    \n",
    "print(\"\\n✅ All Bronze files are now visible to external tools under the 'bronze' schema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4993a",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.2 Silver layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70f43e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating 'silver' schema if it doesn't exist ---\n",
      "  - Schema 'silver' is ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Setup: Create the 'silver' schema ---\n",
    "print(\"--- Creating 'silver' schema if it doesn't exist ---\")\n",
    "con.execute(\"CREATE SCHEMA IF NOT EXISTS silver;\")\n",
    "print(\"  - Schema 'silver' is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a7e945",
   "metadata": {},
   "source": [
    "Cleaned version of mobility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2435675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning mobility data...\n",
      "✓ Cleaning complete!\n",
      "\n",
      "First 5 cleaned rows:\n",
      "   trip_date  hour origin_zone_id destination_zone_id  distance_km  \\\n",
      "0 2023-05-08     3       01009_AM               01001         1.25   \n",
      "1 2023-05-08    18       01009_AM               01001         1.25   \n",
      "2 2023-05-08    19       01009_AM               01001         1.25   \n",
      "3 2023-05-08    20       01009_AM               01001         1.25   \n",
      "4 2023-05-08     7       01009_AM               01001        30.00   \n",
      "\n",
      "   trips_count raw_origin_activity raw_destination_activity  \\\n",
      "0            3           frecuente                     casa   \n",
      "1            6           frecuente                     casa   \n",
      "2            6           frecuente                     casa   \n",
      "3            9           frecuente                     casa   \n",
      "4            3           frecuente                     casa   \n",
      "\n",
      "                                            filename  \\\n",
      "0  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
      "1  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
      "2  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
      "3  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
      "4  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....   \n",
      "\n",
      "               ingestion_timestamp  \n",
      "0 2025-11-15 19:59:19.626101+01:00  \n",
      "1 2025-11-15 19:59:19.626101+01:00  \n",
      "2 2025-11-15 19:59:19.626101+01:00  \n",
      "3 2025-11-15 19:59:19.626101+01:00  \n",
      "4 2025-11-15 19:59:19.626101+01:00  \n",
      "\n",
      "Data types:\n",
      "                column_name               column_type null   key default extra\n",
      "0                 trip_date                      DATE  YES  None    None  None\n",
      "1                      hour                   INTEGER  YES  None    None  None\n",
      "2            origin_zone_id                   VARCHAR  YES  None    None  None\n",
      "3       destination_zone_id                   VARCHAR  YES  None    None  None\n",
      "4               distance_km                    DOUBLE  YES  None    None  None\n",
      "5               trips_count                   INTEGER  YES  None    None  None\n",
      "6       raw_origin_activity                   VARCHAR  YES  None    None  None\n",
      "7  raw_destination_activity                   VARCHAR  YES  None    None  None\n",
      "8                  filename                   VARCHAR  YES  None    None  None\n",
      "9       ingestion_timestamp  TIMESTAMP WITH TIME ZONE  YES  None    None  None\n"
     ]
    }
   ],
   "source": [
    "# Clean the mobility data\n",
    "print(\"Cleaning mobility data...\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "-- Create cleaned version of mobility data\n",
    "CREATE OR REPLACE VIEW silver.cleaned_mobility AS\n",
    "SELECT\n",
    "    -- Fix dates (convert 20230508 → 2023-05-08)\n",
    "    CAST(\n",
    "        SUBSTR(fecha, 1, 4) || '-' || \n",
    "        SUBSTR(fecha, 5, 2) || '-' || \n",
    "        SUBSTR(fecha, 7, 2) \n",
    "    AS DATE) as trip_date,\n",
    "    \n",
    "    -- Fix hour (ensure it's a number)\n",
    "    CAST(periodo AS INTEGER) as hour,\n",
    "    \n",
    "    -- Clean zone IDs\n",
    "    TRIM(CAST(origen AS VARCHAR)) as origin_zone_id,\n",
    "    TRIM(CAST(destino AS VARCHAR)) as destination_zone_id,\n",
    "    \n",
    "    -- Clean distance (handle messy values)\n",
    "    CASE \n",
    "        WHEN distancia ~ '^[0-9]+\\\\.?[0-9]*$' THEN CAST(distancia AS DOUBLE)  -- Normal numbers\n",
    "        WHEN distancia = '0.5-2' THEN 1.25  -- Specific case: use average\n",
    "        WHEN distancia = '2-10' THEN 6.0    -- Specific case: use average  \n",
    "        WHEN distancia = '10-50' THEN 30.0  -- Specific case: use average\n",
    "        WHEN distancia = '>50' THEN 75.0    -- Specific case: estimate\n",
    "        ELSE NULL  -- Can't convert? Set to NULL\n",
    "    END as distance_km,\n",
    "    \n",
    "    -- Clean trips (ensure it's a number)\n",
    "    CAST(viajes AS INTEGER) as trips_count,\n",
    "    \n",
    "    -- Keep other columns as-is for now\n",
    "    actividad_origen as raw_origin_activity,\n",
    "    actividad_destino as raw_destination_activity,\n",
    "    filename,\n",
    "    ingestion_timestamp\n",
    "\n",
    "FROM bronze.mobility_sample_week\n",
    "WHERE \n",
    "    -- Remove bad records\n",
    "    fecha IS NOT NULL \n",
    "    AND origen IS NOT NULL \n",
    "    AND destino IS NOT NULL \n",
    "    AND viajes IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# STEP 2: Check our results\n",
    "print(\"✓ Cleaning complete!\")\n",
    "print(\"\\nFirst 5 cleaned rows:\")\n",
    "result = con.execute(\"SELECT * FROM silver.cleaned_mobility LIMIT 5\").df()\n",
    "print(result)\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "schema = con.execute(\"DESCRIBE silver.cleaned_mobility\").df()\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d155286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA QUALITY CHECKS ===\n",
      "\n",
      "1. Distance values summary:\n",
      "   total_records  records_with_distance  avg_distance  min_distance  \\\n",
      "0      134726205              134726205     13.968322          1.25   \n",
      "\n",
      "   max_distance  \n",
      "0          75.0  \n",
      "\n",
      "2. Sample of unique zone IDs (check for formatting):\n",
      "  origin_zone_id\n",
      "0        0801904\n",
      "1        0818404\n",
      "2          08123\n",
      "3        1716002\n",
      "4        0800701\n",
      "5        0804603\n",
      "6          08234\n",
      "7          08221\n",
      "8        0826304\n",
      "9          08204\n",
      "\n",
      "3. Date range:\n",
      "  start_date   end_date\n",
      "0 2023-05-08 2023-05-14\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA QUALITY CHECKS ===\")\n",
    "\n",
    "# Check for any remaining data issues\n",
    "print(\"\\n1. Distance values summary:\")\n",
    "dist_check = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_records,\n",
    "        COUNT(distance_km) as records_with_distance,\n",
    "        AVG(distance_km) as avg_distance,\n",
    "        MIN(distance_km) as min_distance,\n",
    "        MAX(distance_km) as max_distance\n",
    "    FROM silver.cleaned_mobility\n",
    "\"\"\").df()\n",
    "print(dist_check)\n",
    "\n",
    "print(\"\\n2. Sample of unique zone IDs (check for formatting):\")\n",
    "zones_check = con.execute(\"\"\"\n",
    "    SELECT DISTINCT origin_zone_id \n",
    "    FROM silver.cleaned_mobility \n",
    "    LIMIT 10\n",
    "\"\"\").df()\n",
    "print(zones_check)\n",
    "\n",
    "print(\"\\n3. Date range:\")\n",
    "date_range = con.execute(\"\"\"\n",
    "    SELECT MIN(trip_date) as start_date, MAX(trip_date) as end_date \n",
    "    FROM silver.cleaned_mobility\n",
    "\"\"\").df()\n",
    "print(date_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b82685",
   "metadata": {},
   "source": [
    "Clean Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7c16a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning population data...\n",
      "\n",
      "Sample of raw population data:\n",
      "    column0  column1\n",
      "0     01001   2925.0\n",
      "1     01002  10307.0\n",
      "2  01004_AM   3005.0\n",
      "3  01009_AM   4599.0\n",
      "4     01010   2951.0\n",
      "\n",
      "Column names in population data:\n",
      "   cid     name     type  notnull dflt_value     pk\n",
      "0    0  column0  VARCHAR    False       None  False\n",
      "1    1  column1  VARCHAR    False       None  False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Cleaning population data...\")\n",
    "\n",
    "# First, let's check what the raw population data looks like\n",
    "print(\"\\nSample of raw population data:\")\n",
    "pop_sample = con.execute(\"SELECT * FROM bronze.population_districts LIMIT 5\").df()\n",
    "print(pop_sample)\n",
    "\n",
    "print(\"\\nColumn names in population data:\")\n",
    "pop_columns = con.execute(\"PRAGMA table_info(bronze.population_districts)\").df()\n",
    "print(pop_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef82e9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning population data...\n",
      "✓ Population data cleaned!\n",
      "\n",
      "First 5 cleaned population rows:\n",
      "    zone_id  population_count\n",
      "0     01001              2925\n",
      "1     01002             10307\n",
      "2  01004_AM              3005\n",
      "3  01009_AM              4599\n",
      "4     01010              2951\n",
      "\n",
      "Data types:\n",
      "        column_name column_type null   key default extra\n",
      "0           zone_id     VARCHAR  YES  None    None  None\n",
      "1  population_count     INTEGER  YES  None    None  None\n",
      "\n",
      "Population data quality summary:\n",
      "   total_records  records_with_population  records_with_null_population  \\\n",
      "0           3792                     3743                            49   \n",
      "\n",
      "   avg_population  \n",
      "0    12659.659898  \n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning population data...\")\n",
    "\n",
    "# Create cleaned population table\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW silver.cleaned_population AS\n",
    "SELECT\n",
    "    -- Clean zone IDs (remove any whitespace)\n",
    "    TRIM(CAST(column0 AS VARCHAR)) as zone_id,\n",
    "    \n",
    "    -- Clean population count (handle 'NA' values and convert to integer)\n",
    "    CASE \n",
    "        WHEN column1 = 'NA' THEN NULL\n",
    "        WHEN TRIM(column1) = '' THEN NULL\n",
    "        ELSE CAST(CAST(column1 AS DOUBLE) AS INTEGER)\n",
    "    END as population_count\n",
    "\n",
    "FROM bronze.population_districts\n",
    "WHERE \n",
    "    -- Remove records with missing zone IDs\n",
    "    column0 IS NOT NULL \n",
    "    AND column1 IS NOT NULL\n",
    "    AND TRIM(column0) != ''  -- Remove empty zone IDs\n",
    "\"\"\")\n",
    "\n",
    "# Verify the results\n",
    "print(\"✓ Population data cleaned!\")\n",
    "print(\"\\nFirst 5 cleaned population rows:\")\n",
    "result = con.execute(\"SELECT * FROM silver.cleaned_population LIMIT 5\").df()\n",
    "print(result)\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "schema = con.execute(\"DESCRIBE silver.cleaned_population\").df()\n",
    "print(schema)\n",
    "\n",
    "print(\"\\nPopulation data quality summary:\")\n",
    "quality_check = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_records,\n",
    "        COUNT(population_count) as records_with_population,\n",
    "        COUNT(*) - COUNT(population_count) as records_with_null_population,\n",
    "        AVG(population_count) as avg_population\n",
    "    FROM silver.cleaned_population\n",
    "\"\"\").df()\n",
    "print(quality_check)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6bc879",
   "metadata": {},
   "source": [
    "Combine cleaned tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f494c07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating integrated OD table with demographics...\n",
      "✓ Integrated table created!\n",
      "\n",
      "First 5 rows of integrated data:\n",
      "   trip_date  hour origin_zone_id destination_zone_id  distance_km  \\\n",
      "0 2023-05-08    14        0301406             0309002         30.0   \n",
      "1 2023-05-08    14        0301407             0309002         30.0   \n",
      "2 2023-05-08    18        0301407             0309002         30.0   \n",
      "3 2023-05-08     6        0301408             0309002         30.0   \n",
      "4 2023-05-08     8        0301408             0309002         30.0   \n",
      "\n",
      "   trips_count  origin_population  destination_population raw_origin_activity  \\\n",
      "0           13              51182                   13266           frecuente   \n",
      "1           10              29705                   13266           frecuente   \n",
      "2            7              29705                   13266           frecuente   \n",
      "3            2              39381                   13266           frecuente   \n",
      "4            2              39381                   13266           frecuente   \n",
      "\n",
      "  raw_destination_activity                                           filename  \n",
      "0                     casa  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....  \n",
      "1                     casa  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....  \n",
      "2                     casa  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....  \n",
      "3                     casa  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....  \n",
      "4                     casa  ../data/raw\\\\mitma\\\\20230508_Viajes_distritos....  \n",
      "\n",
      "Join quality check:\n",
      "   total_trips  trips_with_origin_population  \\\n",
      "0    134726205                     134402517   \n",
      "\n",
      "   trips_with_destination_population  \n",
      "0                          134401830  \n"
     ]
    }
   ],
   "source": [
    "print(\"Creating integrated OD table with demographics...\")\n",
    "\n",
    "# Create the integrated table by joining mobility and population data\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW silver.silver_integrated_od AS\n",
    "SELECT\n",
    "    -- Mobility data\n",
    "    m.trip_date,\n",
    "    m.hour,\n",
    "    m.origin_zone_id,\n",
    "    m.destination_zone_id,\n",
    "    m.distance_km,\n",
    "    m.trips_count,\n",
    "    \n",
    "    -- Population data for ORIGIN zone\n",
    "    orig_pop.population_count as origin_population,\n",
    "    \n",
    "    -- Population data for DESTINATION zone  \n",
    "    dest_pop.population_count as destination_population,\n",
    "    \n",
    "    -- Keep raw values for reference\n",
    "    m.raw_origin_activity,\n",
    "    m.raw_destination_activity,\n",
    "    m.filename\n",
    "\n",
    "FROM silver.cleaned_mobility m\n",
    "LEFT JOIN silver.cleaned_population orig_pop \n",
    "    ON m.origin_zone_id = orig_pop.zone_id\n",
    "LEFT JOIN silver.cleaned_population dest_pop \n",
    "    ON m.destination_zone_id = dest_pop.zone_id\n",
    "\"\"\")\n",
    "\n",
    "# Verify the results\n",
    "print(\"✓ Integrated table created!\")\n",
    "print(\"\\nFirst 5 rows of integrated data:\")\n",
    "result = con.execute(\"SELECT * FROM silver.silver_integrated_od LIMIT 5\").df()\n",
    "print(result)\n",
    "\n",
    "print(\"\\nJoin quality check:\")\n",
    "join_quality = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_trips,\n",
    "        COUNT(origin_population) as trips_with_origin_population,\n",
    "        COUNT(destination_population) as trips_with_destination_population\n",
    "    FROM silver.silver_integrated_od\n",
    "\"\"\").df()\n",
    "print(join_quality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade62f9",
   "metadata": {},
   "source": [
    "## 5. Gold Layer Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a874d263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating 'gold' schema if it doesn't exist ---\n",
      "  - Schema 'gold' is ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Setup: Create the 'gold' schema ---\n",
    "print(\"--- Creating 'gold' schema if it doesn't exist ---\")\n",
    "con.execute(\"CREATE SCHEMA IF NOT EXISTS gold;\")\n",
    "print(\"  - Schema 'gold' is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d24f294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ View 'gold.hourly_mobility_patterns' created successfully.\n",
      "\n",
      "--- Verifying the 'gold.hourly_mobility_patterns' view (Corrected) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>total_avg_trips_in_madrid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [hour, total_avg_trips_in_madrid]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This query answers Business Question 1.\n",
    "# It has been UPDATED to read from silver.silver_integrated_od and\n",
    "# to derive the province_code from the origin_zone_id.\n",
    "\n",
    "gold_hourly_patterns_query = \"\"\"\n",
    "CREATE OR REPLACE VIEW gold.hourly_mobility_patterns AS\n",
    "WITH daily_patterns AS (\n",
    "    SELECT\n",
    "        EXTRACT(isodow FROM trip_date) AS day_of_week,\n",
    "        hour,\n",
    "        origin_zone_id,\n",
    "        destination_zone_id,\n",
    "        trips_count\n",
    "    FROM silver.silver_integrated_od\n",
    ")\n",
    "SELECT\n",
    "    CASE \n",
    "        WHEN day_of_week <= 5 THEN 'weekday'\n",
    "        ELSE 'weekend'\n",
    "    END AS day_type,\n",
    "    hour,\n",
    "    origin_zone_id,\n",
    "    destination_zone_id,\n",
    "    AVG(trips_count) AS avg_trips\n",
    "FROM daily_patterns\n",
    "GROUP BY 1, 2, 3, 4;\n",
    "\"\"\"\n",
    "con.execute(gold_hourly_patterns_query)\n",
    "print(\"✅ View 'gold.hourly_mobility_patterns' created successfully.\")\n",
    "\n",
    "# --- Corrected Verification ---\n",
    "# We will use a subquery to get the province_name for filtering. This is a bit\n",
    "# more complex but correctly uses the data we have.\n",
    "print(\"\\n--- Verifying the 'gold.hourly_mobility_patterns' view (Corrected) ---\")\n",
    "madrid_pattern_query = \"\"\"\n",
    "-- We need a lookup from province code to province name for our filter\n",
    "WITH province_lookup AS (\n",
    "    SELECT DISTINCT\n",
    "        SUBSTRING(\"Provincias\", 1, 2) AS province_code,\n",
    "        SUBSTRING(\"Provincias\", 4) AS province_name\n",
    "    FROM bronze.gdp_provinces\n",
    "    WHERE \"Periodo\" = '2022' AND \"Provincias\" NOT LIKE 'Total%' AND LENGTH(\"Provincias\") > 3\n",
    ")\n",
    "SELECT\n",
    "    gp.hour,\n",
    "    SUM(gp.avg_trips) as total_avg_trips_in_madrid\n",
    "FROM gold.hourly_mobility_patterns AS gp\n",
    "-- Join to the lookup table using the province code from the origin_zone_id\n",
    "JOIN province_lookup AS pl ON SUBSTRING(gp.origin_zone_id, 1, 2) = pl.province_code\n",
    "WHERE pl.province_name = 'Madrid'\n",
    "  AND gp.day_type = 'weekday'\n",
    "GROUP BY gp.hour\n",
    "ORDER BY gp.hour;\n",
    "\"\"\"\n",
    "display(con.execute(madrid_pattern_query).df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66954858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Views 'gold.province_economics' and 'gold.gravity_model_inputs' created successfully.\n",
      "\n",
      "--- Verifying the 'gold.gravity_model_inputs' view ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_zone_id</th>\n",
       "      <th>destination_zone_id</th>\n",
       "      <th>total_actual_trips</th>\n",
       "      <th>avg_distance_km</th>\n",
       "      <th>origin_population</th>\n",
       "      <th>destination_province_gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2807908</td>\n",
       "      <td>2807908</td>\n",
       "      <td>2442194.0</td>\n",
       "      <td>3.434795</td>\n",
       "      <td>247327</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0801910</td>\n",
       "      <td>0801910</td>\n",
       "      <td>2144993.0</td>\n",
       "      <td>2.549900</td>\n",
       "      <td>238245</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2807911</td>\n",
       "      <td>2807911</td>\n",
       "      <td>1890866.0</td>\n",
       "      <td>2.675785</td>\n",
       "      <td>258064</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0801902</td>\n",
       "      <td>0801902</td>\n",
       "      <td>1886197.0</td>\n",
       "      <td>2.516749</td>\n",
       "      <td>264353</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2807916</td>\n",
       "      <td>2807916</td>\n",
       "      <td>1804357.0</td>\n",
       "      <td>3.060398</td>\n",
       "      <td>192809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>04902</td>\n",
       "      <td>04902</td>\n",
       "      <td>1771652.0</td>\n",
       "      <td>7.559942</td>\n",
       "      <td>84005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2807913</td>\n",
       "      <td>2807913</td>\n",
       "      <td>1559203.0</td>\n",
       "      <td>2.680747</td>\n",
       "      <td>238577</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0704004</td>\n",
       "      <td>0704004</td>\n",
       "      <td>1494921.0</td>\n",
       "      <td>4.893642</td>\n",
       "      <td>151206</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28106</td>\n",
       "      <td>28106</td>\n",
       "      <td>1340829.0</td>\n",
       "      <td>3.024372</td>\n",
       "      <td>131689</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2807910</td>\n",
       "      <td>2807910</td>\n",
       "      <td>1330275.0</td>\n",
       "      <td>2.852121</td>\n",
       "      <td>239693</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  origin_zone_id destination_zone_id  total_actual_trips  avg_distance_km  \\\n",
       "0        2807908             2807908           2442194.0         3.434795   \n",
       "1        0801910             0801910           2144993.0         2.549900   \n",
       "2        2807911             2807911           1890866.0         2.675785   \n",
       "3        0801902             0801902           1886197.0         2.516749   \n",
       "4        2807916             2807916           1804357.0         3.060398   \n",
       "5          04902               04902           1771652.0         7.559942   \n",
       "6        2807913             2807913           1559203.0         2.680747   \n",
       "7        0704004             0704004           1494921.0         4.893642   \n",
       "8          28106               28106           1340829.0         3.024372   \n",
       "9        2807910             2807910           1330275.0         2.852121   \n",
       "\n",
       "   origin_population  destination_province_gdp  \n",
       "0             247327                       NaN  \n",
       "1             238245                       NaN  \n",
       "2             258064                       NaN  \n",
       "3             264353                       NaN  \n",
       "4             192809                       NaN  \n",
       "5              84005                       NaN  \n",
       "6             238577                       NaN  \n",
       "7             151206                       NaN  \n",
       "8             131689                       NaN  \n",
       "9             239693                       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This query answers Business Question 2.\n",
    "# UPDATED to use your existing Silver views.\n",
    "\n",
    "gold_gravity_model_query = \"\"\"\n",
    "-- First, create a lookup for provincial GDP\n",
    "CREATE OR REPLACE VIEW gold.province_economics AS\n",
    "SELECT\n",
    "    SUBSTRING(\"Provincias\", 1, 2) AS province_code,\n",
    "    SUBSTRING(\"Provincias\", 4) AS province_name,\n",
    "    TRY_CAST(REPLACE(REPLACE(Total, '.', ''), ',', '.') AS DOUBLE) AS gdp_euros\n",
    "FROM bronze.gdp_provinces\n",
    "WHERE \"Periodo\" = '2022'\n",
    "  AND \"Provincias\" NOT LIKE 'Total%'\n",
    "  AND LENGTH(\"Provincias\") > 3;\n",
    "\n",
    "-- Now, build the main gravity model input view\n",
    "CREATE OR REPLACE VIEW gold.gravity_model_inputs AS\n",
    "WITH od_summary AS (\n",
    "    SELECT\n",
    "        origin_zone_id,\n",
    "        destination_zone_id,\n",
    "        SUM(trips_count) AS total_actual_trips,\n",
    "        AVG(distance_km) AS avg_distance_km,\n",
    "        -- Get population from the already-joined data\n",
    "        ANY_VALUE(origin_population) AS origin_population -- Use ANY_VALUE as it's the same for all trips in the group\n",
    "    FROM silver.silver_integrated_od\n",
    "    GROUP BY 1, 2\n",
    ")\n",
    "SELECT\n",
    "    od.origin_zone_id,\n",
    "    od.destination_zone_id,\n",
    "    od.total_actual_trips,\n",
    "    od.avg_distance_km,\n",
    "    od.origin_population,\n",
    "    -- Get Destination Economic Activity (Ej) by joining our new economics view\n",
    "    econ.gdp_euros AS destination_province_gdp\n",
    "FROM od_summary AS od\n",
    "LEFT JOIN gold.province_economics AS econ\n",
    "    ON SUBSTRING(od.destination_zone_id, 1, 2) = econ.province_code;\n",
    "\"\"\"\n",
    "con.execute(gold_gravity_model_query)\n",
    "print(\"✅ Views 'gold.province_economics' and 'gold.gravity_model_inputs' created successfully.\")\n",
    "\n",
    "# --- Corrected Verification ---\n",
    "print(\"\\n--- Verifying the 'gold.gravity_model_inputs' view ---\")\n",
    "display(con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM gold.gravity_model_inputs\n",
    "    WHERE total_actual_trips > 100\n",
    "    ORDER BY total_actual_trips DESC\n",
    "    LIMIT 10;\n",
    "\"\"\").df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bb8abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
